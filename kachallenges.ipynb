{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:29:24.538931Z",
     "iopub.status.busy": "2025-05-06T13:29:24.538438Z",
     "iopub.status.idle": "2025-05-06T13:32:33.515753Z",
     "shell.execute_reply": "2025-05-06T13:32:33.514975Z",
     "shell.execute_reply.started": "2025-05-06T13:29:24.538887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install pip3-autoremove\n",
    "# !pip-autoremove torch torchvision torchaudio -y\n",
    "# !pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:32:33.517736Z",
     "iopub.status.busy": "2025-05-06T13:32:33.517434Z",
     "iopub.status.idle": "2025-05-06T13:33:04.575745Z",
     "shell.execute_reply": "2025-05-06T13:33:04.575069Z",
     "shell.execute_reply.started": "2025-05-06T13:32:33.517714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported, FastLanguageModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLAMA 3.2 1B Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:46:54.852430Z",
     "iopub.status.busy": "2025-05-06T13:46:54.851854Z",
     "iopub.status.idle": "2025-05-06T13:47:33.764689Z",
     "shell.execute_reply": "2025-05-06T13:47:33.764146Z",
     "shell.execute_reply.started": "2025-05-06T13:46:54.852405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection.\n",
    "load_in_4bit = True # 4bit quantization to reduce memory usage. \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    #token = \"\" HF_Token for gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add LoRA Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:34:24.674481Z",
     "iopub.status.busy": "2025-05-06T13:34:24.674284Z",
     "iopub.status.idle": "2025-05-06T13:34:31.198041Z",
     "shell.execute_reply": "2025-05-06T13:34:31.197198Z",
     "shell.execute_reply.started": "2025-05-06T13:34:24.674466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Training Data and Merge with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:35:11.702469Z",
     "iopub.status.busy": "2025-05-06T13:35:11.701695Z",
     "iopub.status.idle": "2025-05-06T13:35:12.235454Z",
     "shell.execute_reply": "2025-05-06T13:35:12.234791Z",
     "shell.execute_reply.started": "2025-05-06T13:35:11.702436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"without Adverse Drug Events\",\n",
    "    1: \"with Adverse Drug Events\"\n",
    "}\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"./data/en_train_data_SMM4H_2025_clean.csv\")\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=20)\n",
    "\n",
    "train[\"instruction\"] = \"Classify this math problem into two topics: with Adverse Drug Events and without. Adverse Drug Events are negative medical side effects associated with a drug\"\n",
    "train[\"label\"] = train[\"label\"].map(label_map)\n",
    "train = train.rename(columns={\"label\": \"output\", \"text\": \"input\"})\n",
    "train.to_csv(\"train_updated.csv\", index=False)\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"train_updated.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:35:18.549094Z",
     "iopub.status.busy": "2025-05-06T13:35:18.548679Z",
     "iopub.status.idle": "2025-05-06T13:35:18.668824Z",
     "shell.execute_reply": "2025-05-06T13:35:18.668075Z",
     "shell.execute_reply.started": "2025-05-06T13:35:18.549062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        text = prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:33:53.578459Z",
     "iopub.status.busy": "2025-05-05T20:33:53.578199Z",
     "iopub.status.idle": "2025-05-05T20:33:53.583976Z",
     "shell.execute_reply": "2025-05-05T20:33:53.583173Z",
     "shell.execute_reply.started": "2025-05-05T20:33:53.578440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:33:56.286531Z",
     "iopub.status.busy": "2025-05-05T20:33:56.286271Z",
     "iopub.status.idle": "2025-05-05T20:33:56.291233Z",
     "shell.execute_reply": "2025-05-05T20:33:56.290377Z",
     "shell.execute_reply.started": "2025-05-05T20:33:56.286512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:36:53.969661Z",
     "iopub.status.busy": "2025-05-06T13:36:53.969119Z",
     "iopub.status.idle": "2025-05-06T13:36:54.124014Z",
     "shell.execute_reply": "2025-05-06T13:36:54.123457Z",
     "shell.execute_reply.started": "2025-05-06T13:36:53.969637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 642,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show current memory stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:36:15.041252Z",
     "iopub.status.busy": "2025-05-06T13:36:15.040476Z",
     "iopub.status.idle": "2025-05-06T13:36:15.046852Z",
     "shell.execute_reply": "2025-05-06T13:36:15.046256Z",
     "shell.execute_reply.started": "2025-05-06T13:36:15.041221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:36:56.442996Z",
     "iopub.status.busy": "2025-05-06T13:36:56.442387Z",
     "iopub.status.idle": "2025-05-06T13:36:59.277535Z",
     "shell.execute_reply": "2025-05-06T13:36:59.276464Z",
     "shell.execute_reply.started": "2025-05-06T13:36:56.442962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model (Just LoRA Adapters) and Tokenzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T07:02:17.443028Z",
     "iopub.status.busy": "2025-04-30T07:02:17.442713Z",
     "iopub.status.idle": "2025-04-30T07:02:18.390855Z",
     "shell.execute_reply": "2025-04-30T07:02:18.390177Z",
     "shell.execute_reply.started": "2025-04-30T07:02:17.443005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Saved Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T07:04:02.631516Z",
     "iopub.status.busy": "2025-04-30T07:04:02.630766Z",
     "iopub.status.idle": "2025-04-30T07:04:02.635141Z",
     "shell.execute_reply": "2025-04-30T07:04:02.634414Z",
     "shell.execute_reply.started": "2025-04-30T07:04:02.631488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection.\n",
    "load_in_4bit = True # 4bit quantization to reduce memory usage. \n",
    "\n",
    "# if False:\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"lora_model\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions on Comptetion Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:48:23.314982Z",
     "iopub.status.busy": "2025-05-06T13:48:23.314662Z",
     "iopub.status.idle": "2025-05-06T13:48:23.378191Z",
     "shell.execute_reply": "2025-05-06T13:48:23.377638Z",
     "shell.execute_reply.started": "2025-05-06T13:48:23.314956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/en_train_data_SMM4H_2025_clean.csv\")\n",
    "_, val = train_test_split(train, test_size=0.2, random_state=20)\n",
    "public_set = val\n",
    "public_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:52:42.103070Z",
     "iopub.status.busy": "2025-05-06T13:52:42.102509Z",
     "iopub.status.idle": "2025-05-06T14:29:50.191777Z",
     "shell.execute_reply": "2025-05-06T14:29:50.190929Z",
     "shell.execute_reply.started": "2025-05-06T13:52:42.103043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "public_set[\"instruction\"] = \"Classify this math problem into two topics: with Adverse Drug Events and without. Adverse Drug Events are negative medical side effects associated with a drug\"\n",
    "public_set.rename(columns = {\"text\": \"input\"}, inplace=True)\n",
    "\n",
    "raw_outputs = []\n",
    "for i in tqdm(range(len(public_set))):\n",
    "  inputs = tokenizer(\n",
    "  [\n",
    "      prompt.format(\n",
    "          public_set.iloc[0][\"instruction\"], \n",
    "          public_set.iloc[i][\"input\"], \n",
    "          \"\",\n",
    "      )\n",
    "  ], return_tensors = \"pt\", truncation = True, max_length = 2048).to(\"cuda\")\n",
    "\n",
    "  outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "  raw_outputs.append(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(output):\n",
    "    # re_match = re.search(r'### Response:\\n(.*?)<\\|end▁of▁sentence\\|>', output, re.DOTALL)\n",
    "    re_match = re.search(r'### Response:\\n(.*?)</s>', output, re.DOTALL)\n",
    "    if re_match:\n",
    "        response = re_match.group(1).strip()\n",
    "        return response\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:34:38.093448Z",
     "iopub.status.busy": "2025-05-06T14:34:38.092719Z",
     "iopub.status.idle": "2025-05-06T14:34:38.099541Z",
     "shell.execute_reply": "2025-05-06T14:34:38.098791Z",
     "shell.execute_reply.started": "2025-05-06T14:34:38.093424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "public_set[\"raw_outputs\"] = [raw_output[0] for raw_output in raw_outputs]\n",
    "print(public_set[\"raw_outputs\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parse_output(public_set[\"raw_outputs\"].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:38:16.327034Z",
     "iopub.status.busy": "2025-05-06T14:38:16.326297Z",
     "iopub.status.idle": "2025-05-06T14:38:16.345509Z",
     "shell.execute_reply": "2025-05-06T14:38:16.344805Z",
     "shell.execute_reply.started": "2025-05-06T14:38:16.327008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "public_set[\"parsed_outputs\"] = public_set[\"raw_outputs\"].apply(parse_output)\n",
    "public_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:38:22.483043Z",
     "iopub.status.busy": "2025-05-06T14:38:22.482420Z",
     "iopub.status.idle": "2025-05-06T14:38:22.487539Z",
     "shell.execute_reply": "2025-05-06T14:38:22.486958Z",
     "shell.execute_reply.started": "2025-05-06T14:38:22.483021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"without Adverse Drug Events\",\n",
    "    1: \"with Adverse Drug Events\"\n",
    "}\n",
    "\n",
    "label2id = {v:k for k,v in label_map.items()}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:38:25.049542Z",
     "iopub.status.busy": "2025-05-06T14:38:25.048789Z",
     "iopub.status.idle": "2025-05-06T14:38:25.060301Z",
     "shell.execute_reply": "2025-05-06T14:38:25.059569Z",
     "shell.execute_reply.started": "2025-05-06T14:38:25.049519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "public_set[\"predicted_label\"] = public_set[\"parsed_outputs\"].map(label2id)\n",
    "public_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission to the Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:38:30.843188Z",
     "iopub.status.busy": "2025-05-06T14:38:30.842487Z",
     "iopub.status.idle": "2025-05-06T14:38:30.859613Z",
     "shell.execute_reply": "2025-05-06T14:38:30.858842Z",
     "shell.execute_reply.started": "2025-05-06T14:38:30.843155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "public_set[\"label\"] = public_set[\"label\"].fillna(0).astype(int)\n",
    "public_set.rename(columns = {\"input\": \"text\"})\n",
    "public_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:38:37.670504Z",
     "iopub.status.busy": "2025-05-06T14:38:37.670233Z",
     "iopub.status.idle": "2025-05-06T14:38:37.686393Z",
     "shell.execute_reply": "2025-05-06T14:38:37.685808Z",
     "shell.execute_reply.started": "2025-05-06T14:38:37.670483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "public_set[[\"Question\", \"label\", \"predicted_label\"]].to_csv(\"submission.csv\", index=False)\n",
    "prediction = pd.read_csv(\"submission.csv\")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, prediced_labels = prediction['label'].values, prediction['predicted_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             precision_score, \n",
    "                             recall_score, \n",
    "                             f1_score, \n",
    "                             confusion_matrix, \n",
    "                             classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy = accuracy_score(prediced_labels, true_labels)\n",
    "validation_precision = precision_score(prediced_labels, true_labels)\n",
    "validation_recall = recall_score(prediced_labels, true_labels)\n",
    "validation_f1_micro = f1_score(prediced_labels, true_labels, average='micro')\n",
    "validation_f1_macro = f1_score(prediced_labels, true_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Accuracy: {validation_accuracy}\\n\",\n",
    "    f\"Precision: {validation_precision}\\n\",\n",
    "    f\"Recall: {validation_recall}\\n\",\n",
    "    f\"F1 micro: {validation_f1_micro}\\n\",\n",
    "    f\"F1 macro: {validation_f1_macro}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_labels, prediced_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, prediced_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('default'):  \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
    "                xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11615683,
     "sourceId": 97669,
     "sourceType": "competition"
    },
    {
     "datasetId": 7288830,
     "sourceId": 11618783,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv_unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
